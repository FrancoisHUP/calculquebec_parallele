{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 easy tips to run python code faster  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install numpy scipy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Contiguous Arrays access"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive\n",
    "Here‚Äôs the Python code for the naive matrix multiplication algorithm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def naive_matrix_multiplication(A, B):\n",
    "    N = A.shape[0]\n",
    "    C = np.zeros((N, N))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explanation\n",
    "\n",
    "In the inner loop where the operation ```C[i, j] += A[i, k] * B[k, j]``` is performed, the iteration occurs over the indices ùëñ,ùëó and ùëò. The access patterns for ```C[i, j]``` and ```A[i, k]``` are efficient since the iterations proceed row-wise first, followed by column-wise access, aligning well with memory layout.\n",
    "\n",
    "However, the access pattern for ```B[k, j]``` is problematic. Here, memory is accessed column-wise instead of row-wise. This access pattern is inefficient because it requires the program to load data from different rows into memory, which can lead to a significant number of cache misses, thereby degrading performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"contiguous.png\" style=\"width:80vw; max-width:1200px\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 1 \n",
    "\n",
    "This solution involves transposing the content of \n",
    "ùêµ to improve cache locality when accessing elements of \n",
    "ùêµ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming A and B are already defined as numpy arrays of shape (N, N)\n",
    "def matrix_multiplication_solution1(A, B):\n",
    "    N = A.shape[0]\n",
    "    C = np.zeros((N, N))\n",
    "    B_T = B.T  # Transpose of B\n",
    "    \n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            for k in range(N):\n",
    "                C[i, j] += A[i, k] * B_T[j, k]\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 1: Transposing ùêµ: \n",
    "- Cache Locality: Transposing \n",
    "ùêµ ensures that elements of \n",
    "ùêµ are accessed in a row-major order (which is how they are stored in memory), thus improving cache performance.\n",
    "- Loop Structure: The innermost loop accesses elements of \n",
    "ùêµùëá contiguously, which helps in reducing cache misses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solution 2\n",
    "This solution exchanges the inner for loops to access elements of \n",
    "ùêµ contiguously."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Assuming A and B are already defined as numpy arrays of shape (N, N)\n",
    "def matrix_multiplication_solution2(A, B):\n",
    "    N = A.shape[0]\n",
    "    C = np.zeros((N, N))\n",
    "    \n",
    "    for i in range(N):\n",
    "        for k in range(N):\n",
    "            for j in range(N):\n",
    "                C[i, j] += A[i, k] * B[k, j]\n",
    "    \n",
    "    return C"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution 2: Exchanging Inner Loops:\n",
    "\n",
    "- Cache Locality: By iterating over \n",
    "ùëò before \n",
    "ùëó, elements of \n",
    "ùêµ are accessed contiguously. This helps in leveraging cache lines efficiently because once a cache line is loaded, it can be reused multiple times.\n",
    "- Loop Structure: This structure also improves cache performance by ensuring that elements of \n",
    "ùê¥ and \n",
    "ùêµ are accessed in a cache-friendly manner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Performance Comparison\n",
    "\n",
    "Memory Access Patterns: Both solutions improve memory access patterns compared to a naive matrix multiplication, but Solution 2 tends to have better cache performance in practice because it avoids the need for explicitly transposing \n",
    "ùêµ. Cache Misses: Solution 2 generally results in fewer cache misses since it directly accesses elements of \n",
    "ùêµ in a contiguous manner without needing to create a transposed matrix.\n",
    "\n",
    "Conclusion\n",
    "\n",
    "Solution 2 is likely to run faster in practice. This is because it avoids the overhead of transposing matrix \n",
    "ùêµ and directly ensures that elements of \n",
    "ùêµ are accessed in a cache-friendly manner by iterating over \n",
    "ùëò before ùëó."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "N1=250\n",
    "A = np.random.rand(N1, N1) # image\n",
    "B = np.random.rand(N1, N1) # convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.19 s\n",
      "Wall time: 8.21 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "C_naive = naive_matrix_multiplication(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.14 s\n",
      "Wall time: 8.14 s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "C1 = matrix_multiplication_solution1(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 8.09 s\n",
      "Wall time: 8.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "C2 = matrix_multiplication_solution2(A, B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrices are equal\n",
      "Gain for solution 1: 1.41%\n",
      "Gain for solution 2: 2.68%\n"
     ]
    }
   ],
   "source": [
    "if C_naive.all() == C1.all() == C2.all():\n",
    "    print(\"Matrices are equal\")\n",
    "    print(f\"Gain for solution 1: {(7.08 - 6.98) / 7.08 * 100:.2f}%\")\n",
    "    print(f\"Gain for solution 2: {(7.08 - 6.89) / 7.08 * 100:.2f}%\")\n",
    "else: \n",
    "    print(\"Oups! Matrices are not equal\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** EXTRA DEBBUG TIPS : \n",
    "\n",
    "- You can delete variables that take alot of space in memory with ```del var_name```  if you see your perfomance slowing down. \n",
    "\n",
    "- You can use profile library to check memory leaks or excessive memory usage. \n",
    "\n",
    "- You can use cProfile to see where the time is being spent in your code. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Using a Structure of Vectors instead of Vectors of structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectors of structure (BAD) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Point3D:\n",
    "    def __init__(self, x, y, z):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.z = z\n",
    "\n",
    "    def multiply(self, N):\n",
    "        self.x *= N\n",
    "        self.y *= N\n",
    "        self.z *= N\n",
    "\n",
    "# Create an array of Point3D objects\n",
    "N2 = 1_000_000\n",
    "points = [Point3D(x, y, z) for x, y, z in zip(range(N2), range(N2), range(N2))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure of Vectors (GOOD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Ptr3D:\n",
    "    def __init__(self):\n",
    "        self.x = []\n",
    "        self.y = []\n",
    "        self.z = []\n",
    "    \n",
    "    def resize(self, N):\n",
    "        self.x = [0] * N\n",
    "        self.y = [0] * N\n",
    "        self.z = [0] * N\n",
    "        \n",
    "    def multiply(self, N):\n",
    "        self.x = [x * N for x in self.x]\n",
    "        self.y = [y * N for y in self.y]\n",
    "        self.z = [z * N for z in self.z]\n",
    "\n",
    "# Create a Ptr3D object and resize it\n",
    "N2 = 1_000_000\n",
    "ptr3d = Ptr3D()\n",
    "ptr3d.resize(N2)\n",
    "\n",
    "# Populate the coordinates\n",
    "for i in range(N2):\n",
    "    ptr3d.x[i] = i\n",
    "    ptr3d.y[i] = i\n",
    "    ptr3d.z[i] = i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "In the first version, the point class is use to encapsulate the value for the 3 dimensions. Then we can create a list containing multiple objects of point. In the second version, only one object is created and the object contain all the coordinate of the points.\n",
    "\n",
    "#### Advantages and Disadvantages:\n",
    "\n",
    "**Approach 1:**\n",
    "\n",
    "- Pros: Encapsulation of point coordinates in a single object.\n",
    "\n",
    "- Cons: Potentially higher memory overhead due to object overhead and possibly less cache-friendly.\n",
    "\n",
    "**Approach 2:**\n",
    "\n",
    "- Pros: More cache-friendly since coordinates are stored in contiguous arrays, potentially leading to better performance for some operations.\n",
    "\n",
    "- Cons: Less encapsulation, can be less intuitive to manage as the relationship between x, y, and z is implicit rather than explicit.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to resize "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 219 ms\n",
      "Wall time: 214 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for point in points:\n",
    "    point.multiply(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 172 ms\n",
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ptr3d.multiply(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All points are equal\n",
      "Gain: 42.09%\n"
     ]
    }
   ],
   "source": [
    "# Check if all points are equal\n",
    "comparison_results = all(\n",
    "    ptr3d.x[i] == points[i].x and ptr3d.y[i] == points[i].y and ptr3d.z[i] == points[i].z\n",
    "    for i in range(N2)\n",
    ")\n",
    "\n",
    "# Print the result\n",
    "if comparison_results:\n",
    "    print(\"All points are equal\")\n",
    "    print(f\"Gain: {(297 - 172) / 297 * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"Oops! points are not equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Remove computation from the a loop "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing cumpute from an inner loop can be easy as removing a if statement or calculating a constant outside the loop.  \n",
    "\n",
    "Here Let's take a more complexe example. Let's build tree lists of random number and see if there is a combination of number addition gives our secret number. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "N3=250\n",
    "list1=[random.randint(0, 100) for _ in range(N3)]\n",
    "list2=[random.randint(0, 100) for _ in range(N3)]\n",
    "list3=[random.randint(0, 100) for _ in range(N3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive approach\n",
    "def find_combinations_naive(list1, list2, list3, target_sum):\n",
    "    combinations = set()  # Use a set to store unique combinations\n",
    "    for a in list1:\n",
    "        for b in list2:\n",
    "            for c in list3:\n",
    "                if a + b + c == target_sum:\n",
    "                    combinations.add((a, b, c))  # Add tuple to set\n",
    "    return combinations  # Convert set to list for final output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_combinations_optimized(list1, list2, list3, target_sum):\n",
    "    combinations = set()  # Use a set to store unique combinations\n",
    "    pair_sums = {}\n",
    "    \n",
    "    # Precompute the sum of pairs from list1 and list2\n",
    "    for a in list1:\n",
    "        for b in list2:\n",
    "            pair_sum = a + b\n",
    "            if pair_sum not in pair_sums:\n",
    "                pair_sums[pair_sum] = []\n",
    "            pair_sums[pair_sum].append((a, b))\n",
    "    \n",
    "    # For each element in list3, check if the complement exists in the precomputed sums\n",
    "    for c in list3:\n",
    "        required_sum = target_sum - c\n",
    "        if required_sum in pair_sums:\n",
    "            for (a, b) in pair_sums[required_sum]:\n",
    "                combinations.add((a, b, c))  # Add tuple to set\n",
    "    \n",
    "    return combinations  # Convert set to list for final output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The optimized approach reduces the time complexity from ùëÇ(ùëõ3) to ùëÇ(ùëõ2) by precomputing sums of pairs from list1 and list2 and storing these in a hash map for fast lookups. Here's how it works:\n",
    "\n",
    "**Precompute Pair Sums:** Iterate over list1 and list2 to compute all possible sums and store these in a dictionary (pair_sums), which takes \n",
    "ùëÇ(ùëõ2) time.\n",
    "\n",
    "**Fast Lookup:** Iterate over list3 and for each element c, compute the required complement (target_sum - c). Check if this complement exists in pair_sums using fast dictionary lookups (ùëÇ(1) on average).\n",
    "\n",
    "**Efficiency:** The algorithm immediately returns the first valid combination found, eliminating unnecessary computations.\n",
    "\n",
    "This approach is faster because it significantly reduces the number of combinations to check by leveraging precomputed values and efficient lookups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 578 ms\n",
      "Wall time: 586 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_naive = find_combinations_naive(list1, list2, list3, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 42.1 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_optimal = find_combinations_optimized(list1, list2, list3, 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are equals\n",
      "Gain: 97.50%\n"
     ]
    }
   ],
   "source": [
    "if result_naive== result_optimal:\n",
    "    print(\"Results are equals\")\n",
    "    print(f\"Gain: {(625 - 15.6) / 625 * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"Oops! points are not equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Use math !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can short cut compute time with a little bit of math. You can 1) factorise the equation to its minimum, 2) if its possible you can change the equation to be lighter comptationnally to do or you can use technique that shortcut some compute \n",
    "\n",
    "For example : \n",
    "\n",
    "1\\) Instead of this sum : $ \\sum_{k=0}^{n} k = \\frac{n(n+1)}{2}$ , consider using the short form : $ n * (n + 1) // 2 $\n",
    "\n",
    "2\\) Instead of using the eucledien distance : $d_E = \\sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}$, use the Manthan distance which is alot faster to compute $d_M = |x_2 - x_1| + |y_2 - y_1|$\n",
    "\n",
    "3\\) Let's see an exemple of computationnal shortcut with a convolution :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def naive_convolution(image, kernel):\n",
    "    image_height, image_width = image.shape\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    output_height = image_height - kernel_height + 1\n",
    "    output_width = image_width - kernel_width + 1\n",
    "    output = np.zeros((output_height, output_width))\n",
    "    \n",
    "    for i in range(output_height):\n",
    "        for j in range(output_width):\n",
    "            region = image[i:i+kernel_height, j:j+kernel_width]\n",
    "            output[i, j] = np.sum(region * kernel)\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def fft_convolution(image, kernel):\n",
    "    # Pad the kernel to be the same size as the image\n",
    "    padded_kernel = np.zeros_like(image)\n",
    "    kernel_height, kernel_width = kernel.shape\n",
    "    padded_kernel[:kernel_height, :kernel_width] = kernel\n",
    "    \n",
    "    # Perform FFT on both the image and the padded kernel\n",
    "    image_fft = np.fft.fft2(image)\n",
    "    kernel_fft = np.fft.fft2(padded_kernel)\n",
    "    \n",
    "    # Element-wise multiplication in the frequency domain\n",
    "    convolved_fft = image_fft * kernel_fft\n",
    "    \n",
    "    # Inverse FFT to get the convolved image\n",
    "    convolved_image = np.fft.ifft2(convolved_fft)\n",
    "    \n",
    "    # Taking the real part and cropping the image to the original size\n",
    "    convolved_image = np.real(convolved_image)\n",
    "    \n",
    "    return convolved_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explanation\n",
    "\n",
    "The fast fourrier transform the image into the frequency domain. One this is done you can do the convolution, but since all the frequency are in a signle 2D matrix, you only need to do a matrix multiplpication. With a normal convolution in the spatial doamine, the complexity is the order of ùëÇ(ùëÅ2‚ãÖùêæ2), the FFT-based approach reduces this to ùëÇ(ùëÅ2 log ùëÅ)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.rand(500, 500)\n",
    "kernel = np.array([[1, 0, 0], [0, -1, 0], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.55 s\n",
      "Wall time: 1.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_naive = naive_convolution(image, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 46.9 ms\n",
      "Wall time: 24 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_fft = fft_convolution(image, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are equals\n",
      "Gain: 97.95%\n"
     ]
    }
   ],
   "source": [
    "if result_naive.all()==result_fft.all():\n",
    "    print(\"Results are equals\")\n",
    "    print(f\"Gain: {(1520 - 31.2) / 1520 * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"Oops! convolution are not equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Use libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, the rule of thumb is : if you are thinking about optimizing a function, you are probably not the first one. Plenty of librairy allready exists with optimize code for GPU, multithreaded on CPU and multiprocessing. Library like numpy, numba, openACC, OpenMP, MPI, and more, are build by a little army of developper. \n",
    "\n",
    "Here's yet another version of a convolution using scipy : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.ndimage import convolve\n",
    "\n",
    "def optimized_convolution(image, kernel):\n",
    "    return convolve(image, kernel, mode='constant', cval=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = np.random.rand(500, 500)\n",
    "kernel = np.array([[1, 0, 0], [0, -1, 0], [0, 0, 1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 1.55 s\n",
      "Wall time: 1.55 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_naive = naive_convolution(image, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: total: 0 ns\n",
      "Wall time: 2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "result_optimized = optimized_convolution(image, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are equals\n",
      "Gain: 99.87%\n"
     ]
    }
   ],
   "source": [
    "if result_naive.all()==result_optimized.all():\n",
    "    print(\"Results are equals\")\n",
    "    print(f\"Gain: {(1520 - 2) / 1520 * 100:.2f}%\")\n",
    "else:\n",
    "    print(\"Oops! convolution are not equal\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bonus \n",
    "\n",
    "With compile language, dont try to beat the compiler. These days compiler are pretty good at optimizing your for loop. When you compile the compiler turn you code into assembly and by doing so they can use specials instructions to make the code run faster. If you try to be more sofiticated, there's a risk the compiler might give you worst perfomance. The key is put simple easy to understand code in your for loop.      \n",
    "\n",
    "**Amdahl‚Äôs law** (max gain with parallelization)\n",
    "$$ \\begin{equation}\n",
    "S = \\frac{1}{(1 - P) + \\frac{P}{N}}\n",
    "\\end{equation} $$\n",
    "\n",
    "Where,\n",
    "\n",
    "$S$ : Theorical speedup.\n",
    "\n",
    "$P$ : Proportion of the program that can be parallelized.\n",
    "\n",
    "$N$ : is the number of processors.\n",
    "\n",
    "If 50% of a program can be parallelized (ùëÉ=0.5), and you run it on 4 processors (ùëÅ=4):\n",
    "\n",
    "$$ S = \\frac{1}{(1 - 0.5) + \\frac{0.5}{4}} = \\frac{1}{0.5 + 0.125} = \\frac{1}{0.625} \\approx 1.6 $$\n",
    "\n",
    "So, the maximum speedup in this case would be 1.6 times faster than the original program. This shows that even with an infinite number of processors, the speedup is limited by the portion of the program that cannot be parallelized.\n",
    "\n",
    "Amdahl's Law highlights the diminishing returns of adding more processors to a task that has parts which cannot be parallelized.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
